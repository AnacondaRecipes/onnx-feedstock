{% set name = "onnx" %}
{% set version = "1.13.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/{{ name }}/{{ name }}/archive/v{{ version }}.tar.gz
  sha256: 090d3e10ec662a98a2a72f1bf053f793efc645824f0d4b779e0ce47468a0890e

build:
  number: 0
  entry_points:
    - check-model = onnx.bin.checker:check_model
    - check-node = onnx.bin.checker:check_node
    - backend-test-tools = onnx.backend.test.cmd_tools:main

requirements:
  build:
    - {{ compiler('c') }}                     
    - {{ compiler('cxx') }}                   
    - cmake
    - make                                    # [not win]
    - libprotobuf
  host:
    - python
    - pip
    - setuptools
    - wheel
    - pybind11 2.10.4
    - protobuf
    - libprotobuf
    - pytest-runner 6.0.0
    - numpy   1.19  # [py<310]
    - numpy   1.21  # [py==310]
    - numpy   1.23  # [py>=311]
  run:
    - python
    - protobuf >=3.20.2,<4
    - {{ pin_compatible('libprotobuf') }}
    - {{ pin_compatible('numpy') }}
    - typing-extensions >=3.6.2.1

test:
  requires:
    - pip
  imports:
    - onnx
  commands:
    - pip check
    - check-model --help
    - check-node --help
    - backend-test-tools --help

about:
  home: https://onnx.ai
  summary: Open Neural Network Exchange library
  license: MIT
  license_family: MIT
  license_file: LICENSE
  description: |
    Open Neural Network Exchange (ONNX) is the first step toward an open
    ecosystem that empowers AI developers to choose the right tools as their
    project evolves. ONNX provides an open source format for AI models. It
    defines an extensible computation graph model, as well as definitions of
    built-in operators and standard data types. Initially we focus on the
    capabilities needed for inferencing (evaluation).
  doc_url: https://github.com/onnx/onnx/blob/main/README.md
  dev_url: https://github.com/onnx/onnx

extra:
  recipe-maintainers:
    - ezyang
    - marcelotrevisani
    - xhochy
